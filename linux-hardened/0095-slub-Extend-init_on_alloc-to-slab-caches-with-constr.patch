From 58f7bc7b259fb5c449c635e0c296cadd380f49fd Mon Sep 17 00:00:00 2001
From: Thibaut Sautereau <thibaut.sautereau@ssi.gouv.fr>
Date: Fri, 29 Nov 2019 16:27:14 +0100
Subject: [PATCH 095/102] slub: Extend init_on_alloc to slab caches with
 constructors

This has required some rework during the port to 5.13, due to
da844b787245 ("kasan, mm: integrate slab init_on_alloc with HW_TAGS"),
and the patch is actually quite simpler now since we do not need to
unpoison objects anymore.

Signed-off-by: Levente Polyak <levente@leventepolyak.net>
Signed-off-by: Thibaut Sautereau <thibaut.sautereau@ssi.gouv.fr>
[nicolas.bouchinet@ssi.gouv.fr: pre/post-alloc hooks moved from mm/slab.h to mm/slub.c (see 6011be59910fb12b7)]
Signed-off-by: Nicolas Bouchinet <nicolas.bouchinet@ssi.gouv.fr>
---
 mm/slab.h | 2 ++
 mm/slub.c | 2 ++
 2 files changed, 4 insertions(+)

diff --git a/mm/slab.h b/mm/slab.h
index ebca8fb55a9e..4c9721bd48e1 100644
--- a/mm/slab.h
+++ b/mm/slab.h
@@ -667,8 +667,10 @@ static inline bool slab_want_init_on_alloc(gfp_t flags, struct kmem_cache *c)
 {
 	if (static_branch_maybe(CONFIG_INIT_ON_ALLOC_DEFAULT_ON,
 				&init_on_alloc)) {
+#ifndef CONFIG_SLUB
 		if (c->ctor)
 			return false;
+#endif
 		if (c->flags & (SLAB_TYPESAFE_BY_RCU | SLAB_POISON))
 			return flags & __GFP_ZERO;
 		return true;
diff --git a/mm/slub.c b/mm/slub.c
index cfea6de6972b..e4b17d4940c8 100644
--- a/mm/slub.c
+++ b/mm/slub.c
@@ -4221,6 +4221,8 @@ bool slab_post_alloc_hook(struct kmem_cache *s, struct list_lru *lru,
 		if (p[i] && init && (!kasan_init ||
 				     !kasan_has_integrated_init()))
 			memset(p[i], 0, zero_size);
+		if (p[i] && init && s->ctor)
+			s->ctor(p[i]);
 		kmemleak_alloc_recursive(p[i], s->object_size, 1,
 					 s->flags, init_flags);
 		kmsan_slab_alloc(s, p[i], init_flags);
-- 
2.51.2

